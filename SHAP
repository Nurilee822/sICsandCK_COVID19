# library import
import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

nCar = df.shape[0] # 데이터 개수
nVar = df.shape[1] # 변수 개수
print('nCar: %d' % nCar, 'nVar: %d' % nVar )

feature_columns = list(df.columns.difference(['pneumonia'])) # price-target, 그 외 feature
X = df[feature_columns]
y = df['pneumonia']
train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42)
# train/test 비율을 7:3
print(train_x.shape, test_x.shape, train_y.shape, test_y.shape) # 데이터 확인

# library
import lightgbm as lgb  # 없을 경우 cmd/anaconda prompt에서 install
from math import sqrt
from sklearn.metrics import mean_squared_error

# lightgbm model
lgb_dtrain = lgb.Dataset(data = train_x, label = train_y) # LightGBM 모델에 맞게 변환
lgb_param = {'max_depth': 10,
            'learning_rate': 0.01, # Step Size
            'n_estimators': 1000, # Number of trees
            'objective': 'regression'} # 목적 함수 (L2 Loss)
lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain) # 학습 진행
lgb_model_predict = lgb_model.predict(test_x) # test data 예측
print("RMSE: {}".format(sqrt(mean_squared_error(lgb_model_predict, test_y)))) # RMSE

# shap value
import shap
explainer = shap.TreeExplainer(lgb_model) # Tree model Shap Value 확인 객체 지정
shap_values = explainer.shap_values(test_x) # Shap Values 계산

shap.force_plot(explainer.expected_value, shap_values, test_x)

shap.summary_plot(shap_values, test_x)

shap.summary_plot(shap_values, test_x, plot_type = "bar")
