import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/230316_deathtotal.csv')
df.head()

split_count = int(df.shape[0]*0.8)
split_count

train = df[:split_count].copy()
train.shape

test = df[split_count:].copy()
test.shape

feature_names = train.columns[:-1].tolist()
feature_names

label_name = train.columns[-1]
label_name

X_train = train[feature_names]
print(X_train.shape)
X_train.head()

y_train = train[label_name]
print(y_train.shape)
y_train.head()

X_test = test[feature_names]
print(X_test.shape)
X_test.head()

y_test = test[label_name]
print(y_test.shape)
y_test.head()

from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier()
model

y_pred = model.predict(X_test)
y_pred[:5]

from sklearn.tree import plot_tree
plt.figure(figsize = (20, 10))
plot_tree(model, feature_names = feature_names)

import graphviz
from sklearn.tree import export_graphviz

dot_tree = export_graphviz(model, feature_names = feature_names, filled = True)
graphviz.Source(dot_tree)

model.feature_importances_

plt.figure(figsize = (10, 7))
sns.barplot(x = model.feature_importances_, y = feature_names)
plt.show()

diff_count = abs(y_test - y_pred).sum()
diff_count

abs(y_test - y_pred).sum() / len(y_test)

(len(y_test) - diff_count) / len(y_test) *100

from sklearn.tree import DecisionTreeClassifier

model1=DecisionTreeClassifier(max_features=3)
model1.fit(X_train,y_train)
y1_pred=model1.predict(X_test)

from sklearn import metrics
models=['DecisionTreeClassifier']
accuracy=[y1_pred]

for i,j in zip(models,accuracy):
  print("Accuracy for {} : {}".format(i,metrics.accuracy_score(y_test,j)))

r_probs=[0 for i in range(len(y_test))]
y1_pred_prob=model1.predict_proba(X_test)[::,1]

import matplotlib.pyplot as plt

plt.figure(figsize=(12,6))
plt.plot(fpr1,tpr1,label="DecisionTreeClassifier")

plt.legend(loc=4)
plt.grid(color='b', ls = '-.', lw = 0.25)
plt.show()

auc_score=[metrics.roc_auc_score(y_test,i) for i in [y1_pred_prob] ]
print("auc_score for {} : {}".format(i,metrics.roc_auc_score(y_test,j)))

